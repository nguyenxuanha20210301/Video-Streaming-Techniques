## B.3. Kiến trúc hệ thống streaming

Trong các hệ thống truyền dòng video, kiến trúc hệ thống đóng vai trò quyết định đến khả năng mở rộng (scalability), độ trễ (latency), độ tin cậy (reliability) và chi phí hạ tầng. Ba mô hình kiến trúc điển hình gồm:

- Kiến trúc **Client–Server truyền thống**  
- Kiến trúc **CDN và Edge Caching**  
- Kiến trúc **P2P Streaming** (có thể kết hợp CDN → hybrid P2P-CDN)

Các kiến trúc này không loại trừ lẫn nhau; trên thực tế các nền tảng OTT lớn thường dùng **CDN + ABR trên HTTP** làm nền tảng, kết hợp thêm các kỹ thuật P2P hoặc edge computing trong các kịch bản nhất định.

---

### B.3.1. Mô hình Client–Server truyền thống

#### B.3.1.1. Mô tả tổng quan

Trong mô hình client–server “thuần”, toàn bộ nội dung video được lưu trữ tại một hoặc một cụm server trung tâm (origin server hoặc media server). Mỗi client kết nối trực tiếp (logic) đến server này để:

- yêu cầu nội dung (VoD: Video-on-Demand) hoặc kênh live;  
- nhận luồng dữ liệu (progressive download, HTTP streaming, RTSP/RTP…).

Sơ đồ ASCII đơn giản:

```text
        +-------------------+
        |   Origin Server   |
        | (Media/Web Server)|
        +---------+---------+
                  |
        ----------+---------------------- Internet/Core Network -----------
                  |
      +-----------+-----------+-----------+-----------+
      |           |           |           |           |
   Client 1    Client 2    Client 3    ...        Client N
```

Server chịu trách nhiệm:

* lưu trữ nội dung (storage);
* mã hóa hoặc transcode (online/offline);
* truyền luồng dữ liệu đến từng client.

Đây là kiến trúc phổ biến trong các hệ thống **streaming thế hệ đầu** (RTSP/RTP, Windows Media Server, RealServer) và trong các triển khai nhỏ không dùng CDN.

#### B.3.1.2. Mô hình tải và giới hạn băng thông server

Giả sử:

* $(R_v)$: bitrate video mà mỗi client nhận (bit/s);
* $(N)$: số lượng client đồng thời;
* $(C_s)$: tổng băng thông uplink khả dụng của server (bit/s).

Tải băng thông lên server:

$$
R_{\text{srv}} = N \cdot R_v
$$

Để server không bị nghẽn tại tầng mạng:

$$
N \cdot R_v \le C_s
\quad \Rightarrow \quad
N \le \frac{C_s}{R_v}
$$

Đây là giới hạn **scalability tuyến tính**, nghĩa là chi phí băng thông server tăng tuyến tính theo số người xem. Đối với dịch vụ lớn (hàng trăm nghìn, hàng triệu người xem), mô hình thuần client–server trở nên không khả thi nếu không bổ sung:

* nhân bản nhiều server đặt phân tán;
* hoặc sử dụng **CDN**;
* hoặc dùng **P2P** để offload băng thông lên peers.

Ngoài băng thông, tải CPU/IO của server (đọc file, mã hóa/packaging on-the-fly) cũng tăng theo (N), nhưng trong đa số hệ thống HTTP streaming, **băng thông** mới là nút cổ chai chính.

#### B.3.1.3. Mô hình trễ đầu cuối trong client–server

Tổng độ trễ end-to-end đến client (VoD) có thể tách thành:

$$
T_{\text{total}} = T_{\text{DNS}} + T_{\text{TCP}} + T_{\text{HTTP-req}} + T_{\text{first-byte}} + T_{\text{download}}
$$

Trong đó:

* $(T_{\text{DNS}})$: độ trễ phân giải DNS;
* $(T_{\text{TCP}})$: thiết lập kết nối TCP (3-way handshake);
* $(T_{\text{HTTP-req}})$: gửi request HTTP;
* $(T_{\text{first-byte}})$: thời gian từ khi gửi request đến khi nhận byte đầu tiên (gồm RTT + xử lý server);
* $(T_{\text{download}})$: thời gian tải đủ dữ liệu để bắt đầu phát (liên quan đến **startup buffer**).

Trong kiến trúc client–server thuần, server thường nằm xa phía client (địa lý và topo mạng), dẫn đến RTT lớn và (T_{\text{first-byte}}) tăng; vì vậy mô hình này kém phù hợp cho:

* dịch vụ **global-scale**;
* yêu cầu latency thấp;
* lượng người xem đột biến (flash crowd).

#### B.3.1.4. Nhận xét

Ưu điểm:

* Thiết kế đơn giản, dễ triển khai;
* Dễ kiểm soát bảo mật, DRM, ghi log;
* Phù hợp cho hệ thống quy mô nhỏ hoặc trong mạng cục bộ.

Nhược điểm:

* Khả năng mở rộng kém (server & uplink trở thành bottleneck);
* Latency và jitter lớn khi client ở xa server;
* Khó chống DDoS hoặc flash crowd nếu không có tầng phân phối trung gian.

Kiến trúc này gần như luôn được thay thế hoặc “bọc” bởi **CDN**, **reverse proxy**, hoặc **P2P overlay** trong các hệ thống OTT hiện đại.

---

### B.3.2. CDN và Edge Caching

#### B.3.2.1. Mục tiêu của CDN trong streaming

**Content Delivery Network (CDN)** là hạ tầng phân phối nội dung phân tán, sử dụng nhiều máy chủ **edge** (điểm hiện diện – PoP) đặt gần người dùng nhằm:

* **giảm độ trễ truy cập** (RTT nhỏ hơn, ít hops mạng hơn);
* **giảm tải cho origin server**;
* **tăng khả năng mở rộng** (hàng triệu user đồng thời);
* **cải thiện QoE** cho streaming (startup nhanh, ít stall).

Đối với video streaming, các CDN như Akamai, CloudFront, Cloudflare, Fastly… lưu trữ hoặc cache các **segment** HLS/DASH ở edge, phục vụ trực tiếp tới người xem.

#### B.3.2.2. Kiến trúc phân cấp: Origin – Mid-tier – Edge

Sơ đồ tổng quát:

```text
                 +----------------------+
                 |      Origin Server   |
                 |  (VoD Storage / Live |
                 |   Packager / DRM)    |
                 +----------+-----------+
                            |
                     (CDN Backbone / Mid-tier)
                            |
          +-----------------+------------------+
          |                                    |
   +------+-----+                       +------+-----+
   |  Edge PoP  |                       |  Edge PoP  |
   |   Region A |                       |   Region B |
   +------+-----+                       +------+-----+
          |                                    |
   +------+------+                       +-----+------+
   |  Users in  |                       |  Users in  |
   |   Region A |                       |   Region B |
   +------------+                       +------------+
```

* **Origin**: lưu trữ bản gốc (master) của nội dung, chạy packager HLS/DASH, DRM, ad-insertion,…;
* **Mid-tier** (tùy CDN): tầng trung gian giảm tải truy vấn trực tiếp đến origin, làm “shield” cache;
* **Edge PoP**: gần người dùng nhất; nhận request từ end-user, phục vụ nội dung nếu có cache hit.

**Request routing** (định tuyến yêu cầu đến edge) thường dựa trên:

* DNS-based: ánh xạ tên miền video (vd. `video.example.com`) đến IP của edge gần nhất;
* HTTP redirection: origin/CDN trả 302 đến URL edge;
* Anycast + riêng logic điều phối.

Các CDN thương mại (Akamai, CloudFront) duy trì hàng trăm nghìn server tại hàng nghìn PoP toàn cầu phục vụ chủ yếu cho web và video streaming.

#### B.3.2.3. Mô hình cache hit và tải origin

Giả sử:

* $(N)$: số client;
* $(R_v)$: bitrate video trung bình mỗi client;
* $(H)$: **cache hit ratio** tại edge (tính trên byte hoặc request);
* $((1-H))$: miss ratio;
* $(C_{\text{origin}})$: băng thông uplink khả dụng của origin.

Tải băng thông origin:

$$
R_{\text{origin}} = (1 - H) \cdot N \cdot R_v
$$

Để origin không bị nghẽn:

$$
(1 - H) \cdot N \cdot R_v \le C_{\text{origin}}
$$

Khi (H) tăng (edge cache hiệu quả):

* cùng một (C_{\text{origin}}), hệ thống hỗ trợ được **N** lớn hơn;
* với traffic “hot” (video đang trend), H có thể gần 1 → phần lớn tải được xử lý ở edge.

Trong khi đó, tải băng thông trên **một PoP edge** với (N_{\text{edge}}) user:

$$
R_{\text{edge}} = N_{\text{edge}} \cdot R_v
$$

PoP edge có thể được mở rộng horizontally (nhiều server), và các PoP khác nhau chia sẻ tải toàn cầu.

#### B.3.2.4. Latency decomposition trong CDN

Tổng độ trễ khi dùng CDN có thể mô hình:

$$
T_{\text{total}} = T_{\text{DNS-routing}} + T_{\text{RTT-edge}} + T_{\text{processing}} + T_{\text{download}}
$$

* $(T_{\text{DNS-routing}})$: thêm một vài bước để chọn edge phù hợp, nhưng thường không đáng kể so với RTT;
* $(T_{\text{RTT-edge}})$: RTT giữa client và edge, thường nhỏ hơn nhiều so với RTT tới origin;
* $(T_{\text{processing}})$: xử lý HTTP/HTTPS, TLS handshake;
* $(T_{\text{download}})$: thời gian tải segment (phụ thuộc throughput đường truyền và kích thước segment).

Vì **RTT-edge** nhỏ hơn RT-origin, nên:

* (T_{\text{first-byte}}) giảm;
* tốc độ tăng TCP/QUIC nhanh hơn (ít RTT → cửa sổ congestion tăng nhanh), giúp download segment nhanh hơn;
* từ đó startup delay và rebuffering giảm.

#### B.3.2.5. CDN và MPEG-DASH/HLS

Với MPEG-DASH (ISO/IEC 23009-1) và HLS:

* nội dung được cắt thành các segment nhỏ (ví dụ 2–6 s) ở nhiều bitrate/độ phân giải;
* mỗi representation là một chuỗi segment;
* **manifest** (MPD cho DASH, playlist M3U8 cho HLS) liệt kê URL các segment.

Trong mô hình CDN:

* manifest và segment được lưu trên **origin** và được CDN cache hóa;
* client ABR chỉ **gửi HTTP GET** đến hostname của CDN (ví dụ `cdn.example.com/path/seg-0001.m4s`);
* edge CDN sẽ phục vụ trực tiếp nếu có cache hit, hoặc yêu cầu lên origin nếu cache miss.

Điểm đáng chú ý: bản thân chuẩn MPEG-DASH **không yêu cầu** bất kỳ logic đặc biệt nào ở server; server chỉ là HTTP server thông thường. Điều này làm cho DASH/HLS rất phù hợp để kết hợp với CDN: chỉ cần CDN cache các file segment và manifest như các đối tượng tĩnh.

#### B.3.2.6. Edge computing và xử lý “gần người dùng”

Các kiến trúc mới tận dụng **edge computing** để xử lý streaming gần người dùng hơn, ví dụ:

* Transcoding tại edge (edge transcoding) để giảm tải origin;
* ABR-aware caching: ưu tiên lưu các bitrate phổ biến;
* QoE-aware routing: điều chỉnh PoP phục vụ dựa trên chất lượng thực tế.

Các mô hình tối ưu mới thường xem xét đồng thời:

* tối thiểu hóa latency;
* tối đa hóa cache hit;
* giảm chi phí backhaul;
* đảm bảo fairness giữa users.

---

### B.3.3. P2P Streaming

#### B.3.3.1. Động lực sử dụng P2P cho streaming

Trong kiến trúc client–server thuần (kể cả khi có CDN), **chi phí băng thông** chủ yếu do nhà cung cấp dịch vụ gánh. **Peer-to-Peer (P2P)** đưa ra triết lý: **mỗi client đồng thời là server cho các client khác**:

* mỗi peer không chỉ tải video **từ** mạng, mà còn **upload** lại nội dung nhận được cho peers khác;
* băng thông **uplink của người dùng** được tận dụng, giảm chi phí uplink ở origin/CDN;
* giúp tăng khả năng mở rộng (scalability) cho live streaming và VoD.

Các hệ thống IPTV P2P (PPLive, SopCast, CoolStreaming…) là ví dụ điển hình, hỗ trợ hàng trăm nghìn đến hàng triệu người xem sử dụng P2P overlay trên Internet.

#### B.3.3.2. Mô hình năng lực P2P đơn giản

Giả sử một hệ thống P2P streaming có:

* $(N)$: số lượng peers đang xem cùng một luồng;
* $(s)$: bitrate video cần thiết để xem mượt (bit/s);
* $(U_{\text{avg}})$: băng thông upload trung bình của một peer;
* $(C_s)$: băng thông uplink của server gốc (origin/seed).

Tổng năng lực cung cấp dòng video của toàn hệ thống:

$$
C_{\text{total}} = C_s + N \cdot U_{\text{avg}}
$$

Để mọi peer đều nhận đủ bitrate (s), tổng nhu cầu là:

$$
D_{\text{total}} = N \cdot s
$$

Điều kiện khả thi (ở mức độ đơn giản):

$$
C_s + N \cdot U_{\text{avg}} \ge N \cdot s
$$

hay:

$$
N \cdot (s - U_{\text{avg}}) \le C_s
\quad \Rightarrow \quad
N \le \frac{C_s}{s - U_{\text{avg}}}
$$

* Nếu (U_{\text{avg}} \approx s): số peers có thể tăng rất lớn (về lý thuyết), server chỉ cần cung cấp lượng nhỏ ban đầu (seeding, bootstrap);
* Nếu (U_{\text{avg}} < s): cần đủ (C_s) để bù thiếu, hoặc áp dụng cơ chế ưu tiên, layered streaming,…

Dĩ nhiên, mô hình thực tế phức tạp hơn (churn, topology, overhead signaling) nhưng mô hình đơn giản này cho thấy **P2P có thể giảm mạnh tải server** khi uplink users đủ lớn.

#### B.3.3.3. Kiến trúc overlay: tree-based vs mesh-based

Trong P2P streaming, dữ liệu truyền qua **overlay network** (lớp logic) trên hạ tầng IP.

1. **Tree-based overlay**

   * Các peers được tổ chức thành cây phân phối (distribution tree) gốc tại server.
   * Mỗi peer nhận dữ liệu từ “parent” và gửi cho “children”.

   Sơ đồ:

   ```text
                 Source/Server
                       |
                     Peer A
                    /      \
                 Peer B   Peer C
                /     \       \
             Peer D  Peer E   Peer F
   ```

   * Ưu điểm: đơn giản, tối ưu đường truyền đơn (ít trễ);
   * Nhược điểm: dễ tổn thương trước churn – khi một peer ở cao trong cây rời khỏi, cả subtree phía dưới bị gián đoạn.

2. **Mesh-based overlay**

   * Không có cây cố định; mỗi peer kết nối tới nhiều peers khác thành mesh, trao đổi thông tin chunk-availability và kéo (pull) dữ liệu.

   * Kiến trúc điển hình:

   ```text
       Peer A ----- Peer B ----- Peer C
        |   \        |  \         |
        |    \       |   \        |
       Peer D -------+---- Peer E-+
   ```

   * Dữ liệu được chia thành các **chunks** nhỏ; peers trao đổi “buffer map” (danh sách chunk có sẵn) và quyết định tải chunk nào từ peer nào.
   * Ưu điểm: robust trước churn (mất một peer chỉ gây ảnh hưởng nhỏ vì luôn có nhiều neighbor);
   * Nhược điểm: dễ tăng latency vì có nhiều hops és trễ do scheduling chunk chưa tối ưu.

3. **Hybrid (tree-mesh, multi-tree)**

   * Một số hệ thống dùng **nhiều cây** (multi-tree) cho các layer khác nhau trong coded stream; hoặc cây backbone + mesh local để tăng robust.
   * P2P-VoD còn phức tạp hơn vì người xem không đồng bộ thời gian phát.

#### B.3.3.4. Live vs VoD trong P2P streaming

* **P2P Live Streaming**:

  * Nguồn phát là luồng thời gian thực; tất cả peers xem “gần như” đồng bộ;
  * Yêu cầu **end-to-end latency** thấp (vài giây tới vài chục giây);
  * Overlay phải xử lý tốt churn, độ trễ, băng thông không đồng nhất.

* **P2P VoD (Video-on-Demand)**:

  * Mỗi peer có thể bắt đầu xem bất cứ lúc nào, nên “điểm phát” của các peer không đồng bộ;
  * Cần cơ chế tối ưu **chunk scheduling** để peers với “buffer tiến” chia dữ liệu cho peers “buffer lùi”;
  * Yêu cầu QoE (ít stall, chất lượng cao) nhưng latency không quá nhạy như live.

Các survey cho thấy:

* Tree-based thường phù hợp hơn cho live với yêu cầu độ trễ thấp nếu overlay được quản lý tốt;
* Mesh-based có ưu thế về robust và khả năng thích ứng với churn nhưng cần nghiên cứu kỹ để giảm **mesh delay**.

#### B.3.3.5. Mô hình độ trễ trong P2P live streaming (đơn giản)

Giả sử:

* $(d)$: **độ trễ trung bình** mỗi hop overlay (bao gồm truyền và xử lý);
* $(h)$: **số hop overlay** từ source tới một peer bất kỳ;
* $(T_{\text{source}})$: độ trễ mã hóa/ingest tại nguồn;
* $(T_{\text{playout}})$: độ trễ buffer tại peer trước khi play.

Độ trễ end-to-end:

$$
T_{\text{E2E}} \approx T_{\text{source}} + h \cdot d + T_{\text{playout}}
$$

Thiết kế overlay phải:

* giữ (h) nhỏ (overlay có độ sâu nhỏ);
* giảm (d) trên mỗi hop (chọn neighbor topologically gần, có RTT nhỏ);
* chọn (T_{\text{playout}}) đủ lớn để chống jitter nhưng không quá lớn để tránh độ trễ tổng thể tăng.

#### B.3.3.6. So sánh cao cấp P2P vs CDN

**P2P Streaming**:

* Ưu điểm:

  * Tiết kiệm đáng kể băng thông server/CDN;
  * Khả năng mở rộng tốt khi số user tăng;
  * Tận dụng uplink của user.

* Nhược điểm:

  * Kiểm soát QoE khó hơn → phụ thuộc hạ tầng mạng của peers;
  * Phức tạp về triển khai (NAT traversal, churn, bảo mật, DRM);
  * Độ trễ có thể cao và biến động nếu overlay không được thiết kế tốt.

**CDN-based Streaming**:

* Ưu điểm:

  * QoE ổn định, dễ kiểm soát;
  * SLA rõ ràng, vận hành mature;
  * Latency và jitter thấp nhờ edge gần user.

* Nhược điểm:

  * Chi phí băng thông và CDN cao;
  * Khả năng mở rộng phụ thuộc vào hạ tầng CDN (dù rất lớn, nhưng tốn chi phí).

Do đó, nhiều nghiên cứu gần đây tập trung vào **hybrid P2P-CDN**:

* CDN đảm nhiệm vai trò “anchor” và phục vụ khu vực ít peers;
* P2P offload băng thông tại các cụm user đông;
* Cần cơ chế thông minh để quyết định mức độ tải từ CDN vs P2P nhằm tối ưu QoE và chi phí.

---

### Tài liệu tham khảo cho mục B.3 (định dạng IEEE)

[B15] ISO/IEC, *Information Technology – Dynamic Adaptive Streaming over HTTP (DASH) – Part 1: Media Presentation Description and Segment Formats*, ISO/IEC 23009-1, 2019/2022.

[B16] T. Stockhammer, “Dynamic adaptive streaming over HTTP – Standards and design principles,” in *Proc. ACM MMSys*, 2011, pp. 133–144.

[B17] D. Cianci et al., “Redirection and protocol mechanisms in content delivery network-edge computing for adaptive video streaming,” *Appl. Sci.*, vol. 13, no. 9, 2023.

[B18] L. F. S. do Nascimento et al., “FlyCache: Recommendation-driven edge caching architecture for full life cycle video streaming,” *J. Netw. Comput. Appl.*, 2025.

[B19] Y. Liu, Y. Guo, and C. Liang, “A survey on peer-to-peer video streaming systems,” *Peer-to-Peer Netw. Appl.*, vol. 1, no. 1, pp. 18–28, 2008.

[B20] X. Zhang, J. Liu, B. Li, and T.-S. P. Yum, “CoolStreaming/DONet: A data-driven overlay network for live media streaming,” in *Proc. IEEE INFOCOM*, 2005, pp. 2102–2111.

[B21] T. Small, B. Li, and B. Liang, “Scaling laws and tradeoffs in peer-to-peer live multimedia streaming,” in *Proc. ACM Multimedia*, 2006, pp. 539–548.

[B22] M. Hefeeda, “A survey of peer-to-peer live video streaming schemes – An algorithmic perspective,” *Comput. Netw.*, vol. 56, no. 17, pp. 3548–3579, 2012.
